{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelmg to COCO format\n",
    "\n",
    "Labelmg by default creates files in the **Pascal VOC** format. Most of the latest pipelines are\n",
    "expecting the labels in COCO format.\n",
    "\n",
    "1. Pascal VOC format -> coordinates are represented as `(left_top, right_bottom)`\n",
    "2. Labelmg tool produces Pascal voc format.\n",
    "3. COCO expects all the file names should be in number format\n",
    "4. COCO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/train/\"\n",
    "test_dir = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/test/\"\n",
    "template_test = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/templates_test_data_coco/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(f\"{template_test}/1.xml\")\n",
    "root = tree.getroot()\n",
    "fn_child = root.find(\"filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_child.text = \"1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ET.tostring(root).decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def renamefn_to_intfn(data_dir, start=1000):\n",
    "    \"\"\"\n",
    "    @param data_dir: Pascal VOC format generated by labelmg.\n",
    "    @param start: File name start point.\n",
    "    \"\"\"\n",
    "    get_fn = lambda x: \".\".join(x.split(\".\")[:-1])\n",
    "\n",
    "    pp = Path(data_dir)\n",
    "    for fn in glob.glob(f\"{data_dir}/*.xml\"):\n",
    "        p = Path(fn)\n",
    "        root = ET.parse(fn).getroot()\n",
    "        fn_child = root.find(\"filename\")\n",
    "        path_child = root.find(\"path\")\n",
    "        img_fn = fn_child.text\n",
    "        \n",
    "        if not get_fn(p.name).isdigit():\n",
    "            bname = \".\".join(p.name.split(\".\")[:-1])\n",
    "            png = Path(pp / f\"{img_fn}\")\n",
    "            assert png.exists()\n",
    "            \n",
    "            imgfn_split = img_fn.split(\".\")\n",
    "            img, img_ext = \".\".join(imgfn_split[:-1]), imgfn_split[-1]\n",
    "            \n",
    "            p.rename(pp / f\"{start}.xml\")\n",
    "            png.rename(pp / f\"{start}.{img_ext}\")\n",
    "            \n",
    "            # Update the filename reference in new xml \n",
    "            fn_child.text = f\"{start}.{img_ext}\"\n",
    "            path_child.text = f\"{pp/str(start)}.{img_ext}\"\n",
    "            \n",
    "            with open(pp/f\"{start}.xml\", 'w') as f:\n",
    "                f.write(ET.tostring(root).decode(\"utf8\"))\n",
    "            \n",
    "            start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamefn_to_intfn(template_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coco Category Check\n",
    "\n",
    "Ensure the Dataset has correct labels and category ID mapping across train/val/test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann_file = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/train_coco_updated.json\"\n",
    "val_ann_file = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/test_coco_updated.json\"\n",
    "test_ann_file = \"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/templates_test_data_coco_updated.json\"\n",
    "\n",
    "def check_category_id(ann_file):\n",
    "    ann = json.loads(open(ann_file).read())\n",
    "    cat_map = {i[\"id\"] : i[\"name\"] for i in ann[\"categories\"]}\n",
    "    print({(k, cat_map[k]): v for k, v in Counter([i[\"category_id\"] for i in ann[\"annotations\"]]).items()})\n",
    "    return ann[\"categories\"]\n",
    "\n",
    "check_category_id(train_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_category_id(val_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_category_id(test_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter([i[\"category_id\"] for i in ann[\"annotations\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/haridas/projects/mystique/data/train_and_test-2020-Jun-05-coco/train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(\"filename\").count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morph font weight analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/tmp/pic2card.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_coord = (27.74326380342245, 58.549769282341, 284.94907945394516, 86.0945338010788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img = image.crop(bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_img = np.asarray(cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(c_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bin_img = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_img = np.count_nonzero(bin_img)\n",
    "area_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_img = np.zeros(bin_img.shape, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_open = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(morph_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_img =cv2.subtract(bin_img, morph_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv2.erode(bin_img, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(eroded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(skel_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skel_img = cv2.bitwise_or(skel_img, tmp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(skel_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(image: Image, coords) -> str:\n",
    "        \"\"\"\n",
    "        Extract the weight of the each words by\n",
    "        skeletization applying morph operations on\n",
    "        the input image\n",
    "        @param image : input PIL image\n",
    "        @param coords: list of coordinated from which\n",
    "                       text and height should be extracted\n",
    "        @return: weight\n",
    "        \"\"\"\n",
    "        cropped_image = image.crop(coords)\n",
    "        c_img = np.asarray(cropped_image)\n",
    "        \"\"\"\n",
    "        if(image_height/image_width) < 1:\n",
    "            y_scale = round((800/image_width), 2)\n",
    "            x_scale = round((500/image_height), 2)\n",
    "            c_img = cv2.resize(c_img, (0, 0), fx=x_scale, fy=y_scale)\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(c_img, cv2.COLOR_BGR2GRAY)\n",
    "        # Converting input image to binary format\n",
    "        _, img = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "        area_of_img = np.count_nonzero(img)\n",
    "        # creating an empty skeleton\n",
    "        skel = np.zeros(img.shape, np.uint8)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "        # Loop until erosion leads to thinning text in image to singular pixel\n",
    "        images = []\n",
    "        images.append(Image.fromarray(img))\n",
    "        while True:\n",
    "            morph_open = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "            temp = cv2.subtract(img, morph_open)\n",
    "            eroded = cv2.erode(img, kernel)\n",
    "            skel = cv2.bitwise_or(skel, temp)\n",
    "            img = eroded.copy()\n",
    "            \n",
    "            images.append(Image.fromarray(skel))\n",
    "            # if no white pixels left the image has been completely eroded\n",
    "            if cv2.countNonZero(img) == 0:\n",
    "                break\n",
    "        # length of the lines in text\n",
    "        area_of_skel = np.sum(skel)/255\n",
    "        # width of line = area of the line / length of the line\n",
    "        thickness = round(area_of_img/area_of_skel, 2)\n",
    "        return thickness, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "think, inter_images = get_weight(image, bbox_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(inter_images[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(bin_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_img = np.asarray(inter_images[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(proc_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_img[proc_img.nonzero()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
